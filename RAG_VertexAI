import vertexai
from vertexai.preview.generative_models import (
    GenerativeModel,
    GenerationConfig,
    Tool,
    grounding
)
from dataclasses import dataclass, field
from typing import List

# Initialize Vertex AI
vertexai.init(project="prj-cdw-p-aiml-001-0b36", location="us-central1")

@dataclass
class GeminiConfig:
    """Gemini model configurations."""
    project_id: str
    temperature: float = 0.9
    top_p: float = 0.8
    top_k: int = 40
    max_output_tokens: int = 2048
    candidate_count: int = 1
    location: str = "us-central1"
    model_name: str = "gemini-1.5-flash-001"
    system_instruction: List = field(default_factory=list)

def create_tool():
    """Create a retrieval tool for Vertex AI Search."""
    retrieval = grounding.Retrieval(
        grounding.VertexAISearch(
            datastore="mcg-chunks-manual_1731536738260",
            project="prj-cdw-p-aiml-001-0b36",
            location="us",
        )
    )
    return Tool.from_retrieval(retrieval=retrieval)

def gemini_pro_generate_text(content: str, gemini_config: GeminiConfig, tool: Tool):
    """Generate text using Gemini models."""
    vertexai.init(project=gemini_config.project_id, location=gemini_config.location)
    generation_config = GenerationConfig(
        temperature=gemini_config.temperature,
        top_p=gemini_config.top_p,
        top_k=gemini_config.top_k,
        candidate_count=gemini_config.candidate_count,
        max_output_tokens=gemini_config.max_output_tokens,
        response_mime_type="application/json",
    )
    model = GenerativeModel(gemini_config.model_name, system_instruction=gemini_config.system_instruction)
    response = model.generate_content(content, generation_config=generation_config, tools=[tool], stream=False)
    return response.candidates[0].content.parts[0].text

def generate_response(query_text, tool, gemini_config):
    """Generate a response using Gemini and retrieval tools."""
    prompt = f"Answer the following question based on the context retrieved from the datastore:\n\nQuestion: {query_text}"
    try:
        return gemini_pro_generate_text(content=prompt, gemini_config=gemini_config, tool=tool)
    except Exception as e:
        return f"Error generating response: {str(e)}"

# Example usage
tool = create_tool()
gemini_config = GeminiConfig(
    project_id="prj-cdw-p-aiml-001-0b36",
    model_name="gemini-1.5-flash-001",
    temperature=0.0,
    max_output_tokens=8000,
    top_p=0.1,
    top_k=10,
    location="us-central1",
)
user_query = "What are symptoms of heart disease?"
response = generate_response(user_query, tool, gemini_config)
print(response)
